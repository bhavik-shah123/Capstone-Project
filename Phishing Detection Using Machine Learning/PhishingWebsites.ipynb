{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing Website Detection using Neural Network\n",
    "The aim of the experiments conducted in this notebook is to give an idea of how modern _phishing website attacks_ can be prevented using machine learning. To do this, we are going to use the [Phishing Websites' Dataset](https://archive.ics.uci.edu/ml/datasets/phishing+websites). \n",
    "\n",
    "Initially URLs from the dataset were broken down to numerical values using the file \"Feature Extraction\" which classifies and assigns values based on the research performed during the Capstone Project. Once that was done, every result was stored in a CSV file to be used here in this notebook.\n",
    "\n",
    "We will start off the experiments by importing the initial set of Python modules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2QiF7z2tw0L"
   },
   "outputs": [],
   "source": [
    "# Filter the uneccesary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "df = pd.read_csv('csv_result-Phishing_features (1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and basic display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "jktoyjUtt0qA",
    "outputId": "26f1397b-a4bd-47fd-9a4e-c80a5bb2df62"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V6Up5y5uNyi"
   },
   "outputs": [],
   "source": [
    "y = df['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1119
    },
    "colab_type": "code",
    "id": "6j7vssY-vZQj",
    "outputId": "33ed2448-2b43-4b92-b107-50bb28b6f4ff"
   },
   "outputs": [],
   "source": [
    "y=y.replace(-1,0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6FtfTdWvaAz"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "AvBwlZ_mvqwG",
    "outputId": "4aad8761-df8f-4004-88fd-9e478852325c"
   },
   "outputs": [],
   "source": [
    "X.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting data dimensions and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dimension\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data columns\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the distribution of the class labels and preparing a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "classes = Counter(df['Result'].values)\n",
    "classes.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = pd.DataFrame(classes.most_common(), columns=['Class', 'Num_Observations'])\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a basic bar plot of the distribution of the class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "subplot = class_dist.groupby('Class')['Num_Observations'].sum().plot(kind='barh', width=0.2, figsize=(10,8),color=('skyblue','lightgreen'))\n",
    "\n",
    "subplot.set_title('Class distribution of the websites', fontsize = 15)\n",
    "subplot.set_xlabel('Number of Observations', fontsize = 14)\n",
    "subplot.set_ylabel('Class', fontsize = 14)\n",
    "\n",
    "for i in subplot.patches:\n",
    "    subplot.text(i.get_width()+0.1, i.get_y()+0.1, \\\n",
    "                 str(i.get_width()), fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the summary statistics from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the basic information of the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnnoY2BGwPhn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an EarlyStopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to improve the predictive performance with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1 with SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "2BRbLoUz-aG9",
    "outputId": "78b9e1ba-e3ab-4238-8950-f53c209c6130"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_sgd1 = model.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history_sgd1.history['loss']\n",
    "loss_val = history_sgd1.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-1 SGD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_sgd1 = history_sgd1.history['accuracy']\n",
    "acc_val_sgd1 = history_sgd1.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_sgd1, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_sgd1, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-1 SGD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1 with RMSProp Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "sxZHdKZu9_kq",
    "outputId": "5a1aff6c-13c1-4f51-b42c-8663cacb2a3a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_rmsprop1 = model.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "Wz7cBBCr-OSz",
    "outputId": "b9bd0c8d-1b61-4afa-e45c-c0a4c3155034"
   },
   "outputs": [],
   "source": [
    "loss_train = history_rmsprop1.history['loss']\n",
    "loss_val = history_rmsprop1.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-1 RMSProp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_rmsprop1 = history_rmsprop1.history['accuracy']\n",
    "acc_val_rmsprop1 = history_rmsprop1.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_rmsprop1, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_rmsprop1, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-1 RMSProp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-1 with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "OPORwCHdwfac",
    "outputId": "1c420105-88ef-4829-988a-421982083566"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_adam1 = model.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "hebM2ah3-bm7",
    "outputId": "7c67d316-fef1-4a31-bec7-cb61db6e12a6"
   },
   "outputs": [],
   "source": [
    "loss_train = history_adam1.history['loss']\n",
    "loss_val = history_adam1.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-1 Adam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_adam1 = history_adam1.history['accuracy']\n",
    "acc_val_adam1 = history_adam1.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_adam1, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_adam1, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-1 Adam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision between Optimizer for Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "xZN5kvUD_7hh",
    "outputId": "5fee3f6d-d552-4abd-da84-2826767ace61"
   },
   "outputs": [],
   "source": [
    "l=[0.9542,0.9263,0.9446]\n",
    "l1 = ['SGD','RMSProp','Adam']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('Test Accuracy of Model1')\n",
    "plt.xlabel('Optimizers')\n",
    "plt.plot(l1,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2 with Adam Optimizer\n",
    "### Here in Model-2, as we are increasing the number of neurons, we are also using dropout to overcome overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "ufZe7WHBwpQL",
    "outputId": "6065f9a7-9705-4479-c367-61afaf90afe5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_adam2 = model1.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "ToHU7FZd65HI",
    "outputId": "50273d81-79d6-49ca-d9cf-48600eba6802"
   },
   "outputs": [],
   "source": [
    "loss_train = history_adam2.history['loss']\n",
    "loss_val = history_adam2.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-2 Adam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_adam2 = history_adam2.history['accuracy']\n",
    "acc_val_adam2 = history_adam2.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_adam2, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_adam2, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-2 Adam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2 with RMSProp Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "b-zjRtKe_GB6",
    "outputId": "bf80e50c-9a24-45c7-c7dd-6aa07cce6b60"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model1.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_rmsprop2 = model1.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "N3Pfj7Fs_NbG",
    "outputId": "ab1f26ce-a40f-4a41-eece-cb41aea91cc6"
   },
   "outputs": [],
   "source": [
    "loss_train = history_rmsprop2.history['loss']\n",
    "loss_val = history_rmsprop2.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-2 RMSProp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_rmsprop2 = history_rmsprop2.history['accuracy']\n",
    "acc_val_rmsprop2 = history_rmsprop2.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_rmsprop2, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_rmsprop2, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-2 RMSProp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-2 with SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "LVecqZmM_Y54",
    "outputId": "d3eb49a8-9218-402d-bd03-ba1a61877d4b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "model1.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_sgd2 = model1.fit(X_train, y_train, epochs=15,batch_size=1,validation_data=(X_val, y_val),callbacks=[es_cb])\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "43JlFuO-_eYZ",
    "outputId": "356c5b25-7a62-4879-89cd-f6f311572f30"
   },
   "outputs": [],
   "source": [
    "loss_train = history_sgd2.history['loss']\n",
    "loss_val = history_sgd2.history['val_loss']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss of Model-2 SGD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_sgd2 = history_sgd2.history['accuracy']\n",
    "acc_val_sgd2 = history_sgd2.history['val_accuracy']\n",
    "epochs = range(1,16)\n",
    "plt.plot(epochs, acc_train_sgd2, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, acc_val_sgd2, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Accuracy of Model-2 SGD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision between Optimizers for Model-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "0_JgoEGXAX06",
    "outputId": "cd103351-a666-4266-eb62-40c370753f4c"
   },
   "outputs": [],
   "source": [
    "l=[0.9553,0.9523,0.9263]\n",
    "l1 = ['Adam','RMSProp','SGD']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylabel('Test Accuracy of Model1')\n",
    "plt.xlabel('Optimizers')\n",
    "plt.plot(l1,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with SGD Optimizer for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5]\n",
    "plt.plot(acc_val_sgd1,l)\n",
    "plt.plot(acc_val_sgd2,l)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with RMSProp Optimizer for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "id": "CmWPb8mV9gE5",
    "outputId": "c6883889-1584-4490-a266-bd38cb01e4f8"
   },
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5]\n",
    "plt.plot(acc_val_rmsprop1,l)\n",
    "plt.plot(acc_val_rmsprop2,l)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision with Adam Optimizer for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "id": "gUuH0Qk44dEq",
    "outputId": "a7e93733-665a-4b2b-ff99-bae38a272870"
   },
   "outputs": [],
   "source": [
    "l = [1,2,3,4,5]\n",
    "plt.plot(acc_val_adam1,l)\n",
    "plt.plot(acc_val_adam2,l)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Train Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Enhancement with TDLHBA hyperparameters and visualization\n",
    "\n",
    "`TDLHBA` is technique introduced [in this paper](https://dl.acm.org/citation.cfm?id=3227655). We will use hyperparameter values as presented in the paper to see the performance enhancement of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(40, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=30))\n",
    "model_TDLHBA.add(Dense(30, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.0017470)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(X_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(X_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with TDLHBA hyperparameter settings {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 51\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(0, N), history_TDLHBA.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history_TDLHBA.history[\"accuracy\"], label=\"train_acc\")\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy on the dataset (with TDLHBA hyperparameter settings)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"middle\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PhishingWebsites.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
